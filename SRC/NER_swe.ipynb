{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded crf_swe.pickle\n",
      "\n",
      "Give a sentence in Swedish (q to exit): Jag heter Pelle.\n",
      "\n",
      "\n",
      "   TOKEN  POS  NER\n",
      "0    Jag   PN    O\n",
      "1  heter   VB    O\n",
      "2  Pelle   PM  PRS\n",
      "3      .  MAD    O\n",
      "\n",
      "Give a sentence in Swedish (q to exit): q\n",
      "\n",
      "What would it mean if you got to quit?\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import RDRPOS\n",
    "from RDRPOS import *\n",
    "import nltk\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "SENT_COL=\"sent\"\n",
    "TOKEN_COL=\"token\"\n",
    "SHAPE_COL=\"token_shape\"\n",
    "POS_COL=\"pos\"\n",
    "NER_COL=\"ner\"\n",
    "\n",
    "filename=\"crf_swe.pickle\"\n",
    "# filename=\"crf_eng.pickle\"\n",
    "# filename=\"crf_fr.pickle\"\n",
    "\n",
    "file = open(filename, 'rb')\n",
    "crf = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "print(\"Loaded \" + filename )\n",
    "\n",
    "\n",
    "r = RDRPOSTagger()\n",
    "\n",
    "r.constructSCRDRtreeFromRDRfile(\"./model/Swedish.RDR\")\n",
    "\n",
    "DICT = readDictionary(\"./model/Swedish.DICT\")\n",
    "sent = \"\"\n",
    "while True:\n",
    "    print()\n",
    "    sent = input(\"Give a sentence in Swedish (q to exit): \")\n",
    "#     sent = \"Kalle tycker om Sverige.\"\n",
    "    if sent in ['q']:\n",
    "        break\n",
    "    tokenized_sent = nltk.word_tokenize(sent)\n",
    "\n",
    "\n",
    "    split_sent = \"\"\n",
    "    for token in tokenized_sent:\n",
    "        split_sent = split_sent + \" \" + token\n",
    "\n",
    "    posTagged = r.tagRawSentence(DICT, split_sent)\n",
    "    posTaggedSplit=posTagged.split()\n",
    "    tokens=[]\n",
    "    posTags=[]\n",
    "    # print(posTaggedSplit)\n",
    "    for posTaggedToken in posTaggedSplit:\n",
    "        splitToken = posTaggedToken.split(\"/\")\n",
    "        token = splitToken[0]\n",
    "        tokens.append(token)\n",
    "        pos = splitToken[1].split('.')[0]\n",
    "        posTags.append(pos)\n",
    "    # print(tokens)\n",
    "    # print(posTags)\n",
    "#     print(tokens)\n",
    "#     print(posTags)\n",
    "    \n",
    "    data=[]\n",
    "    for i in range(len(tokens)):\n",
    "        word = tokens[i]\n",
    "        pos = posTags[i]\n",
    "        ner = \"unknown\"\n",
    "        data.append([1,word,pos,ner])\n",
    "#     print(data)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = [ SENT_COL, TOKEN_COL, POS_COL, NER_COL ]) \n",
    "\n",
    "\n",
    "    analyseTokens(df)\n",
    "\n",
    "    getter_sent = SentenceGetter(df)\n",
    "    pred_sentence = getter_sent.sentences\n",
    "\n",
    "    X_sent = [sent2features(s) for s in pred_sentence]\n",
    "    # y = [sent2labels(s) for s in sentences]\n",
    "#     print(X_sent)\n",
    "    y_pred = crf.predict(X_sent)[0]\n",
    "#     print(y_pred)\n",
    "    # print(\"done\")\n",
    "    df[NER_COL]=y_pred\n",
    "    df = df.drop([SENT_COL,SHAPE_COL], axis=1)\n",
    "\n",
    "    df.rename(columns={TOKEN_COL:TOKEN_COL.upper(),POS_COL:POS_COL.upper(),NER_COL:NER_COL.upper()}, \n",
    "                     inplace=True)\n",
    "    print(\"\\n\")\n",
    "    print(df)\n",
    "print(\"\\nWhat would it mean if you got to quit?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
