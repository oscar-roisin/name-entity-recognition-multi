# This file must be included at the top.
include $(SPARV_MAKEFILES)/Makefile.config

# Makefile.multi only needs to be included if this Makefile should be used for more
# than one corpus, each located in a subdirectory directly under the current directory.
# include $(SPARV_MAKEFILES)/Makefile.multi

# The internal name of the corpus. Something short and in lowercase. Preferably
# the same name as the directory containing this file. Not used when including Makefile.multi.
corpus =

# The relative path to the XML files
original_dir = $(root)original/xml

# The following line should contain a list (or an expression resulting in a list)
# of all the source files in the original_dir, excluding the file extension and the original_dir path.
# If omitted, all XML files under original_dir will be used as source files.
# files := $(basename $(notdir $(wildcard $(original_dir)/*.xml)))

# If source files are not encoded in UTF-8, specify their encoding here
source_encoding =


# For linked parallel corpora:
# aligned_corpora is a list of linked languages and corpora. Each item in the list
# should consist of the following three parts, separated by "|": language code,
# name of the other corpus, and name of the structural attribute used for linking.
# Example: aligned_corpora := en|mycorpus-en|link:id
# The filenames for the input files need to be the same in the different corpora.
aligned_corpora :=

# The first line below is a list of every positional annotation (word annotation) we want to have
# in the final result. The names here define which rules will be used.
# The prefix "token." is implied, so "baseform" really means "token.baseform".

# The second line defines the names for the above annotations which will be used
# in the resulting CWB corpus.

# The third and fourth line are like the first two, but for structural attributes.
# The names of structural attributes are defined as "struct:attributename". They
# should be listed in the order smallest to biggest (e.g. "sentence" first, "text" last)
vrt_columns_annotations = word pos msd baseform lemgram saldo prefix suffix ref dephead.ref deprel
vrt_columns             = word pos msd lemma    lex     saldo prefix suffix ref dephead     deprel
vrt_structs_annotations = sentence.n paragraph.n sentence.id text.author text.title
vrt_structs             = sentence:n paragraph:n sentence:id text:author text:title


# Specify empty annotations (annotations will which will get empty values for every token)
null_annotations = pos msd

# This setting is only needed if the source material is in different formats. Every
# format should get its own sub-folder under original_dir, and the folder names
# should then be listed here, separated by spaces.
# If this setting is used, you need to make one copy per format of every "xml_*"
# setting below, and add the folder name as a prefix followed by underscore.
# For example, if you define xml_folders as xml_folders = a b, then you need to
# have a_xml_elements, b_xml_elements, a_xml_annotations, b_xml_annotations,
# and so on. The different formats still need to have the same encoding.
xml_folders =

# On the first line, define a whitespace separated list of XML-elements
# (as "element" or "element:attribute") and on the second line a whitespace separated list
# with the same number of annotations (usually named the same as in vrt_annotations, but with
# the prefix "token." for positional attributes).
# All elements and attributes must be in lowercase. ":" in element names must be escaped with a backslash.
# The following annotation names are reserved and may not be used: "vrt", "sql". If your file system
# is case-insensitive, "text" is reserved as well.
# The annotation files will be written in the order specified in these variables, meaning that
# you usually want to list them in the order biggest to smallest (e.g. "text" first, "token" last),
# to avoid problems with some predefined rules.
xml_elements    =
xml_annotations =

# The name of the header element(s) (if any). In lowercase. Full path to header can
# be specified by joining elements with ".". Separate headers using space.
# Any text within this element will not be part of the corpus text.
xml_header =

# Same as above, but for extracting information from a header, making
# structural attributes spanning the whole text. The complete path to the header
# element must be specified, using dots: xml.tag2.tag3.tag_of_interest:attribute
# The path and attributes must be in lowercase. Any "." in a tag name have to be
# escaped: "\."
# Instead of an attribute you can use TEXT, to capture the text content from the
# element: xml.tag2.tag_of_interest:TEXT
# The scope of the annotation will be the scope of the first tag in the path,
# i.e. <xml> in the above example.
xml_headers            =
xml_header_annotations =

# A witespace separated list of XML-elements that can overlap (as "a+b+c d+e").
xml_overlap =
# A witespace separated list of XML-elements and attributes to ignore.
# "a" skips an element.
# "a:b" skips an attribute. "a:*" skips every attribute of an element.
xml_skip =
# Elements to skip if they are empty. Use if there are empty token elements.
xml_skip_empty =
# HTML-entities to ignore and skip
xml_skip_entities =
# Self-close the following elements (for example if the input contains <br> elements).
xml_autoclose =


# Set these to "true" if compression or validation does not work with this corpus.
skip_cwb_compression =
skip_cwb_validation =


# Specify how to tokenize tokens, sentences and paragraphs (if paragraphs exist
# in the source material).
# *_chunk should be an annotation which is a "parent" to the strings that will
# be tokenized. E.g. "sentence" for token, "paragraph" or "text" for sentence.
# More than one chunk can be specified, separated by space.
token_chunk = sentence
token_segmenter = better_word
token_model =

sentence_chunk = paragraph
sentence_segmenter = punkt_sentence
sentence_model = $(punkt_model)

# Specify order of the sentences/paragraphs in the resulting corpus. Set to "position" to
# preserve original order (default), or set to "random" to scramble. Both can not be set
# to "random" at the same time.
sentence_order = position
paragraph_order = position

# Specify order of the sentences/paragraphs in the XML export, if different from above.
# Possible values are "sentence_scrambled", "paragraph_scrambled" or "original".
# If left blank, the order specified by sentence_order and paragraph_order will be used.
export_order =

# Set to "true" to forbid the installation of an export file for this corpus.
no_install_export =

paragraph_chunk = text
paragraph_segmenter = blanklines
paragraph_model =


# The following three variables are used to convert any existing dates to a
# normalized form used internally during queries: YYYYMMDDhhmmss
# Every date has a "from" and a "to", telling the time span of the annotated text.
# datefrom is the annotation containing the existing dates, e.g. text.year
datefrom =

# dateto is the annotation containing the existing dates, e.g. text.year
# If there are no from-to information in the original dates, give the same dates
# to "dateto" as "datefrom".
dateto =

# dateformat specifies the format of the existing date annotation. The format codes
# used can be found at http://docs.python.org/library/datetime.html#strftime-and-strptime-behavior
dateformat =

# datesplitter is only used when the date value contains both a from-date and a to-date,
# and using datesplitter you define the character(s) dividing these two dates.
datesplitter = 

# dateregex can be used to clean up the input string. The content of the first capturing
# group with a value will be used as input, instead of the whole string.
dateregex = 


# NOTE: 'parents' and 'children' below are usually not needed, since the pipeline
# will try to create the needed files automatically, as long as the child is "token".
# Use only if you run into problems and want to override the default behaviour.

# Whitespace separated list of tuples separated by |. Automatically creates
# parents.annotationX.annotationY annotations, for example:
# parents = token|text.title
# would create the annotations parents.token.text, based on the existing
# annotations text.title and token.
# The resulting parent file is needed by structural attributes, in this example
# any "text" attribute.
parents =

# Same as for parents, but for children. The order of the arguments is reversed:
# children = text.title|token
children =

# Whitespace separated list of triples separated by ".". Automatically creates a
# token annotation by linking tokens to the value of a parent. For example:
# token.text.title
# Implies the following:
# - "token.text.title" is the output annotation.
# - "parents.token.text" is the parent relation (created using "parents" above).
# - "text.title" is the annotation from which the values will be read.
# This is usually only needed when you want to convert a structural attribute to a positional.
chains =


# Set to true to disable warnings for missing parents
ignore_missing_parents =


# Any custom rules you define below that should override the default rules, must
# be specified here, by listing the resulting annotations separated by whitespace.
# Example: token.pos token.baseform
custom_rules =

# Custom rules goes here.

# This file must be included at the end.
include $(SPARV_MAKEFILES)/Makefile.rules
